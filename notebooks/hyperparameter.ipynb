{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit7902d3b6b96f4e0481d11ecc1823e43f",
   "display_name": "Python 3.7.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "\n",
    "param_columns = ['val_loss', 'val_mae', 'loss','mae', 'batch_size', 'h_size', 'top_sizes', 'p_drop', 'lr_tree', 'lr_top', 'best_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = pd.read_csv('../results/parameter_tuning_3.csv')\n",
    "params2 = pd.read_csv('../results/parameter_tuning_4.csv')\n",
    "params = pd.concat([params1, params2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    val_loss   val_mae      loss       mae  batch_size  h_size top_sizes  \\\n",
       "79  0.439649  0.486492  0.476537  0.514158           8      10  (16, 16)   \n",
       "62  0.446939  0.498454  0.492815  0.516565           8       8  (16, 16)   \n",
       "54  0.447603  0.502584  0.520825  0.536975           8       8  (16, 16)   \n",
       "71  0.447669  0.483629  0.492194  0.525878           8      10  (16, 16)   \n",
       "47  0.461187  0.517128  0.533471  0.548352           8       3  (16, 16)   \n",
       "52  0.463963  0.513551  0.467517  0.519532           8       8  (16, 16)   \n",
       "76  0.464537  0.511654  0.583582  0.569194           8      10  (16, 16)   \n",
       "74  0.472597  0.503554  0.513962  0.540752          16      10  (16, 16)   \n",
       "82  0.474817  0.505308  0.549912  0.551473          16      10  (16, 16)   \n",
       "60  0.476678  0.516505  0.603220  0.584894           8       8  (16, 16)   \n",
       "70  0.476883  0.539072  0.630487  0.591832           8      10  (16, 16)   \n",
       "58  0.477226  0.512157  0.532020  0.536884          16       8  (16, 16)   \n",
       "68  0.478556  0.520556  0.591344  0.585296           8      10  (16, 16)   \n",
       "42  0.481936  0.499151  0.585530  0.555802          16       3  (16, 16)   \n",
       "78  0.481975  0.513377  0.576899  0.573885           8      10  (16, 16)   \n",
       "66  0.483278  0.498009  0.547020  0.552645          16       8  (16, 16)   \n",
       "63  0.483714  0.508448  0.502431  0.538550           8       8  (16, 16)   \n",
       "36  0.485300  0.522076  0.594290  0.571983           8       3  (16, 16)   \n",
       "55  0.485393  0.520756  0.506107  0.537898           8       8  (16, 16)   \n",
       "83  0.486924  0.517182  0.514049  0.535326          16      10  (16, 16)   \n",
       "\n",
       "    p_drop  lr_tree  lr_top  best_epoch  \n",
       "79    0.15     0.05    0.05          78  \n",
       "62    0.15     0.05    0.01          76  \n",
       "54    0.10     0.05    0.01          47  \n",
       "71    0.10     0.05    0.05          41  \n",
       "47    0.15     0.05    0.05          77  \n",
       "52    0.10     0.01    0.01          57  \n",
       "76    0.15     0.01    0.01          25  \n",
       "74    0.10     0.05    0.01          59  \n",
       "82    0.15     0.05    0.01          71  \n",
       "60    0.15     0.01    0.01          28  \n",
       "70    0.10     0.05    0.01          20  \n",
       "58    0.10     0.05    0.01          48  \n",
       "68    0.10     0.01    0.01          28  \n",
       "42    0.10     0.05    0.01          77  \n",
       "78    0.15     0.05    0.01          24  \n",
       "66    0.15     0.05    0.01          77  \n",
       "63    0.15     0.05    0.05          48  \n",
       "36    0.10     0.01    0.01          32  \n",
       "55    0.10     0.05    0.05          31  \n",
       "83    0.15     0.05    0.05          51  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>val_loss</th>\n      <th>val_mae</th>\n      <th>loss</th>\n      <th>mae</th>\n      <th>batch_size</th>\n      <th>h_size</th>\n      <th>top_sizes</th>\n      <th>p_drop</th>\n      <th>lr_tree</th>\n      <th>lr_top</th>\n      <th>best_epoch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>79</th>\n      <td>0.439649</td>\n      <td>0.486492</td>\n      <td>0.476537</td>\n      <td>0.514158</td>\n      <td>8</td>\n      <td>10</td>\n      <td>(16, 16)</td>\n      <td>0.15</td>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>0.446939</td>\n      <td>0.498454</td>\n      <td>0.492815</td>\n      <td>0.516565</td>\n      <td>8</td>\n      <td>8</td>\n      <td>(16, 16)</td>\n      <td>0.15</td>\n      <td>0.05</td>\n      <td>0.01</td>\n      <td>76</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>0.447603</td>\n      <td>0.502584</td>\n      <td>0.520825</td>\n      <td>0.536975</td>\n      <td>8</td>\n      <td>8</td>\n      <td>(16, 16)</td>\n      <td>0.10</td>\n      <td>0.05</td>\n      <td>0.01</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.447669</td>\n      <td>0.483629</td>\n      <td>0.492194</td>\n      <td>0.525878</td>\n      <td>8</td>\n      <td>10</td>\n      <td>(16, 16)</td>\n      <td>0.10</td>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.461187</td>\n      <td>0.517128</td>\n      <td>0.533471</td>\n      <td>0.548352</td>\n      <td>8</td>\n      <td>3</td>\n      <td>(16, 16)</td>\n      <td>0.15</td>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>0.463963</td>\n      <td>0.513551</td>\n      <td>0.467517</td>\n      <td>0.519532</td>\n      <td>8</td>\n      <td>8</td>\n      <td>(16, 16)</td>\n      <td>0.10</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>0.464537</td>\n      <td>0.511654</td>\n      <td>0.583582</td>\n      <td>0.569194</td>\n      <td>8</td>\n      <td>10</td>\n      <td>(16, 16)</td>\n      <td>0.15</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>0.472597</td>\n      <td>0.503554</td>\n      <td>0.513962</td>\n      <td>0.540752</td>\n      <td>16</td>\n      <td>10</td>\n      <td>(16, 16)</td>\n      <td>0.10</td>\n      <td>0.05</td>\n      <td>0.01</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>0.474817</td>\n      <td>0.505308</td>\n      <td>0.549912</td>\n      <td>0.551473</td>\n      <td>16</td>\n      <td>10</td>\n      <td>(16, 16)</td>\n      <td>0.15</td>\n      <td>0.05</td>\n      <td>0.01</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>0.476678</td>\n      <td>0.516505</td>\n      <td>0.603220</td>\n      <td>0.584894</td>\n      <td>8</td>\n      <td>8</td>\n      <td>(16, 16)</td>\n      <td>0.15</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>0.476883</td>\n      <td>0.539072</td>\n      <td>0.630487</td>\n      <td>0.591832</td>\n      <td>8</td>\n      <td>10</td>\n      <td>(16, 16)</td>\n      <td>0.10</td>\n      <td>0.05</td>\n      <td>0.01</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>0.477226</td>\n      <td>0.512157</td>\n      <td>0.532020</td>\n      <td>0.536884</td>\n      <td>16</td>\n      <td>8</td>\n      <td>(16, 16)</td>\n      <td>0.10</td>\n      <td>0.05</td>\n      <td>0.01</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>0.478556</td>\n      <td>0.520556</td>\n      <td>0.591344</td>\n      <td>0.585296</td>\n      <td>8</td>\n      <td>10</td>\n      <td>(16, 16)</td>\n      <td>0.10</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>0.481936</td>\n      <td>0.499151</td>\n      <td>0.585530</td>\n      <td>0.555802</td>\n      <td>16</td>\n      <td>3</td>\n      <td>(16, 16)</td>\n      <td>0.10</td>\n      <td>0.05</td>\n      <td>0.01</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>0.481975</td>\n      <td>0.513377</td>\n      <td>0.576899</td>\n      <td>0.573885</td>\n      <td>8</td>\n      <td>10</td>\n      <td>(16, 16)</td>\n      <td>0.15</td>\n      <td>0.05</td>\n      <td>0.01</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>0.483278</td>\n      <td>0.498009</td>\n      <td>0.547020</td>\n      <td>0.552645</td>\n      <td>16</td>\n      <td>8</td>\n      <td>(16, 16)</td>\n      <td>0.15</td>\n      <td>0.05</td>\n      <td>0.01</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>0.483714</td>\n      <td>0.508448</td>\n      <td>0.502431</td>\n      <td>0.538550</td>\n      <td>8</td>\n      <td>8</td>\n      <td>(16, 16)</td>\n      <td>0.15</td>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0.485300</td>\n      <td>0.522076</td>\n      <td>0.594290</td>\n      <td>0.571983</td>\n      <td>8</td>\n      <td>3</td>\n      <td>(16, 16)</td>\n      <td>0.10</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>0.485393</td>\n      <td>0.520756</td>\n      <td>0.506107</td>\n      <td>0.537898</td>\n      <td>8</td>\n      <td>8</td>\n      <td>(16, 16)</td>\n      <td>0.10</td>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>0.486924</td>\n      <td>0.517182</td>\n      <td>0.514049</td>\n      <td>0.535326</td>\n      <td>16</td>\n      <td>10</td>\n      <td>(16, 16)</td>\n      <td>0.15</td>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>51</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "params[param_columns].sort_values('val_loss').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    val_loss  batch_size  h_size          top_sizes\n",
       "26  0.571741          80      64           (16, 16)\n",
       "32  0.591271          80      64         (128, 128)\n",
       "14  0.596732          80      32           (16, 16)\n",
       "20  0.598801          80      32         (128, 128)\n",
       "29  0.614792          80      64       (32, 64, 32)\n",
       "11  0.656769          80       8  (128, 64, 32, 16)\n",
       "23  0.660107          80      32  (128, 64, 32, 16)\n",
       "8   0.664102          80       8         (128, 128)\n",
       "35  0.668442          80      64  (128, 64, 32, 16)\n",
       "5   0.675904          80       8       (32, 64, 32)\n",
       "2   0.686262          80       8           (16, 16)\n",
       "17  0.709663          80      32       (32, 64, 32)"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>val_loss</th>\n      <th>batch_size</th>\n      <th>h_size</th>\n      <th>top_sizes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26</th>\n      <td>0.571741</td>\n      <td>80</td>\n      <td>64</td>\n      <td>(16, 16)</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.591271</td>\n      <td>80</td>\n      <td>64</td>\n      <td>(128, 128)</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.596732</td>\n      <td>80</td>\n      <td>32</td>\n      <td>(16, 16)</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.598801</td>\n      <td>80</td>\n      <td>32</td>\n      <td>(128, 128)</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.614792</td>\n      <td>80</td>\n      <td>64</td>\n      <td>(32, 64, 32)</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.656769</td>\n      <td>80</td>\n      <td>8</td>\n      <td>(128, 64, 32, 16)</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.660107</td>\n      <td>80</td>\n      <td>32</td>\n      <td>(128, 64, 32, 16)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.664102</td>\n      <td>80</td>\n      <td>8</td>\n      <td>(128, 128)</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0.668442</td>\n      <td>80</td>\n      <td>64</td>\n      <td>(128, 64, 32, 16)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.675904</td>\n      <td>80</td>\n      <td>8</td>\n      <td>(32, 64, 32)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.686262</td>\n      <td>80</td>\n      <td>8</td>\n      <td>(16, 16)</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.709663</td>\n      <td>80</td>\n      <td>32</td>\n      <td>(32, 64, 32)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "exps.loc[exps['batch_size'] == 80, ['val_loss', 'batch_size', 'h_size', 'top_sizes']].sort_values('val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    val_loss  batch_size  h_size          top_sizes\n",
       "24  0.500457          10      64           (16, 16)\n",
       "0   0.509104          10       8           (16, 16)\n",
       "12  0.511554          10      32           (16, 16)\n",
       "6   0.521355          10       8         (128, 128)\n",
       "9   0.522516          10       8  (128, 64, 32, 16)\n",
       "25  0.524694          25      64           (16, 16)\n",
       "16  0.525395          25      32       (32, 64, 32)\n",
       "3   0.527689          10       8       (32, 64, 32)\n",
       "7   0.529102          25       8         (128, 128)\n",
       "4   0.533104          25       8       (32, 64, 32)\n",
       "18  0.539047          10      32         (128, 128)\n",
       "30  0.541070          10      64         (128, 128)\n",
       "31  0.543917          25      64         (128, 128)\n",
       "21  0.545346          10      32  (128, 64, 32, 16)\n",
       "33  0.547095          10      64  (128, 64, 32, 16)\n",
       "15  0.547965          10      32       (32, 64, 32)\n",
       "13  0.548327          25      32           (16, 16)\n",
       "27  0.549949          10      64       (32, 64, 32)\n",
       "28  0.551785          25      64       (32, 64, 32)\n",
       "19  0.553361          25      32         (128, 128)\n",
       "26  0.571741          80      64           (16, 16)\n",
       "34  0.581178          25      64  (128, 64, 32, 16)\n",
       "1   0.584493          25       8           (16, 16)\n",
       "10  0.586495          25       8  (128, 64, 32, 16)\n",
       "32  0.591271          80      64         (128, 128)\n",
       "14  0.596732          80      32           (16, 16)\n",
       "20  0.598801          80      32         (128, 128)\n",
       "22  0.612494          25      32  (128, 64, 32, 16)\n",
       "29  0.614792          80      64       (32, 64, 32)\n",
       "11  0.656769          80       8  (128, 64, 32, 16)\n",
       "23  0.660107          80      32  (128, 64, 32, 16)\n",
       "8   0.664102          80       8         (128, 128)\n",
       "35  0.668442          80      64  (128, 64, 32, 16)\n",
       "5   0.675904          80       8       (32, 64, 32)\n",
       "2   0.686262          80       8           (16, 16)\n",
       "17  0.709663          80      32       (32, 64, 32)"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>val_loss</th>\n      <th>batch_size</th>\n      <th>h_size</th>\n      <th>top_sizes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24</th>\n      <td>0.500457</td>\n      <td>10</td>\n      <td>64</td>\n      <td>(16, 16)</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.509104</td>\n      <td>10</td>\n      <td>8</td>\n      <td>(16, 16)</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.511554</td>\n      <td>10</td>\n      <td>32</td>\n      <td>(16, 16)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.521355</td>\n      <td>10</td>\n      <td>8</td>\n      <td>(128, 128)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.522516</td>\n      <td>10</td>\n      <td>8</td>\n      <td>(128, 64, 32, 16)</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.524694</td>\n      <td>25</td>\n      <td>64</td>\n      <td>(16, 16)</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.525395</td>\n      <td>25</td>\n      <td>32</td>\n      <td>(32, 64, 32)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.527689</td>\n      <td>10</td>\n      <td>8</td>\n      <td>(32, 64, 32)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.529102</td>\n      <td>25</td>\n      <td>8</td>\n      <td>(128, 128)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.533104</td>\n      <td>25</td>\n      <td>8</td>\n      <td>(32, 64, 32)</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.539047</td>\n      <td>10</td>\n      <td>32</td>\n      <td>(128, 128)</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.541070</td>\n      <td>10</td>\n      <td>64</td>\n      <td>(128, 128)</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.543917</td>\n      <td>25</td>\n      <td>64</td>\n      <td>(128, 128)</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.545346</td>\n      <td>10</td>\n      <td>32</td>\n      <td>(128, 64, 32, 16)</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.547095</td>\n      <td>10</td>\n      <td>64</td>\n      <td>(128, 64, 32, 16)</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.547965</td>\n      <td>10</td>\n      <td>32</td>\n      <td>(32, 64, 32)</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.548327</td>\n      <td>25</td>\n      <td>32</td>\n      <td>(16, 16)</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.549949</td>\n      <td>10</td>\n      <td>64</td>\n      <td>(32, 64, 32)</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.551785</td>\n      <td>25</td>\n      <td>64</td>\n      <td>(32, 64, 32)</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.553361</td>\n      <td>25</td>\n      <td>32</td>\n      <td>(128, 128)</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.571741</td>\n      <td>80</td>\n      <td>64</td>\n      <td>(16, 16)</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0.581178</td>\n      <td>25</td>\n      <td>64</td>\n      <td>(128, 64, 32, 16)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.584493</td>\n      <td>25</td>\n      <td>8</td>\n      <td>(16, 16)</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.586495</td>\n      <td>25</td>\n      <td>8</td>\n      <td>(128, 64, 32, 16)</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.591271</td>\n      <td>80</td>\n      <td>64</td>\n      <td>(128, 128)</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.596732</td>\n      <td>80</td>\n      <td>32</td>\n      <td>(16, 16)</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.598801</td>\n      <td>80</td>\n      <td>32</td>\n      <td>(128, 128)</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.612494</td>\n      <td>25</td>\n      <td>32</td>\n      <td>(128, 64, 32, 16)</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.614792</td>\n      <td>80</td>\n      <td>64</td>\n      <td>(32, 64, 32)</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.656769</td>\n      <td>80</td>\n      <td>8</td>\n      <td>(128, 64, 32, 16)</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.660107</td>\n      <td>80</td>\n      <td>32</td>\n      <td>(128, 64, 32, 16)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.664102</td>\n      <td>80</td>\n      <td>8</td>\n      <td>(128, 128)</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0.668442</td>\n      <td>80</td>\n      <td>64</td>\n      <td>(128, 64, 32, 16)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.675904</td>\n      <td>80</td>\n      <td>8</td>\n      <td>(32, 64, 32)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.686262</td>\n      <td>80</td>\n      <td>8</td>\n      <td>(16, 16)</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.709663</td>\n      <td>80</td>\n      <td>32</td>\n      <td>(32, 64, 32)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "exps[['val_loss', 'batch_size', 'h_size', 'top_sizes']].sort_values('val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}